{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1087,
     "status": "ok",
     "timestamp": 1620978912913,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 420
    },
    "id": "hPZ1jrOMhqZa",
    "outputId": "0de69e5f-e39f-4599-bdce-4598688a7bf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "       Unnamed: 0           Passwords\n",
      "0               0        Aabacus3417!\n",
      "1               1    Babdomen2849410@\n",
      "2               2     Cabdominal1889$\n",
      "3               3         Dabide0758%\n",
      "4               4       Eabiding7988*\n",
      "...           ...                 ...\n",
      "15535       15535        Nzero664790@\n",
      "15536       15536    Ozestfully42710$\n",
      "15537       15537        Pzesty31810%\n",
      "15538       15538  Qzigzagged2932108*\n",
      "15539       15539       Rzipfile4701_\n",
      "\n",
      "[15540 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "path = \"/content/drive/MyDrive/gtown-passwords/autoencoder/\"\n",
    "\n",
    "passwords = pd.read_csv(path + \"data/15000passwords.csv\", dtype={'Numeric': str})\n",
    "print(passwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot Character Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1158,
     "status": "ok",
     "timestamp": 1620978926902,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 420
    },
    "id": "7hQpuqedCmCK",
    "outputId": "6a5b4e57-3032-4d4c-e247-2e3a9d75e5a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "71\n",
      "(15540, 22)\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "###  Pad & Tokenize Passwords  ###\n",
    "##################################\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Identify max password length in dataset and pad rest of the passwords such that all of them have the same length.\n",
    "# Haveing same length sequences is a requirement for LSTM\n",
    "PAD_CHAR = \"~\"\n",
    "PASS_LENGTH = max([len(p) for p in passwords[\"Passwords\"]])\n",
    "\n",
    "padded_passwords = []\n",
    "charset = set(PAD_CHAR)               # start with the initial padding char\n",
    "for p in passwords[\"Passwords\"]:\n",
    "  padded_passwords.append(p.ljust(PASS_LENGTH, PAD_CHAR))\n",
    "  charset |= set(p)                   # |= is the union set operation.\n",
    "\n",
    "# Convert characters to integers \n",
    "vocab_size = len(charset)\n",
    "char2id = dict((c, i) for i, c in enumerate(charset))\n",
    "\n",
    "# One hot encode the passwords\n",
    "encoded_passwords = [[char2id[c] for c in password] for password in padded_passwords]\n",
    "one_hot_encoded = np.array([to_categorical(p, num_classes=vocab_size) for p in encoded_passwords])\n",
    "\n",
    "print(PASS_LENGTH)\n",
    "print(vocab_size)\n",
    "print(np.shape(encoded_passwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCuhe7txgiaQ"
   },
   "source": [
    "Variational Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1620978931985,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 420
    },
    "id": "ozdw0mcxBiK2"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "###  Create VAE Model  ###\n",
    "##########################\n",
    "from keras import objectives\n",
    "from keras import backend as K\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input, Lambda, Layer, Bidirectional\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "\n",
    "def create_lstm_vae(timesteps, layer_sizes, vocab_size, epsilon_std=1.,\n",
    "                    batch_size=10):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(layer_sizes[-1],),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(.5 * z_log_sigma) * epsilon\n",
    "  \n",
    "  # Create encoder model\n",
    "  enc_input = Input(batch_shape=(batch_size, timesteps, vocab_size))\n",
    "  x = enc_input\n",
    "  for idx, layer_size in enumerate(layer_sizes):\n",
    "    ret_seq = (idx != len(layer_sizes) - 1) # False for the last layer_size\n",
    "    x = Bidirectional(LSTM(layer_size, return_sequences=ret_seq))(x)\n",
    "  enc_output = Dense(layer_sizes[-1], activation=\"relu\")(x)\n",
    "  z_mean = Dense(layer_sizes[-1])(enc_output)\n",
    "  z_log_sigma = Dense(layer_sizes[-1])(enc_output)\n",
    "  z = Lambda(sampling, output_shape=(layer_sizes[-1],))([z_mean, z_log_sigma])\n",
    "  encoder = Model(enc_input, z_mean, name=\"Encoder\")\n",
    "\n",
    "  # Create decoder model\n",
    "  bottleneck_size = layer_sizes[-1]\n",
    "  dec_input = Input((bottleneck_size,))\n",
    "  layer = RepeatVector(timesteps)\n",
    "  x = layer(z)\n",
    "  _x = layer(dec_input)\n",
    "  for layer_size in layer_sizes[::-1][1:]:\n",
    "    layer = Bidirectional(LSTM(layer_size, return_sequences=True))\n",
    "    x = layer(x)\n",
    "    _x = layer(_x)\n",
    "  layer =  TimeDistributed(Dense(vocab_size, activation=\"softmax\"))\n",
    "  dec_output = layer(x)\n",
    "  _dec_output = layer(_x)\n",
    "  decoder = Model(dec_input, _dec_output, name=\"Decoder\")\n",
    "\n",
    "  # connected_decoder = decoder(z_mean)\n",
    "\n",
    "  # Create autoencoder model\n",
    "  autoencoder = Model(enc_input, dec_output, name=\"Autoencoder\")\n",
    "  # autoencoder = Model(enc_input, connected_decoder, name=\"Autoencoder\")\n",
    "\n",
    "  # Variational autoencoder custom loss categorical entropy loss + KL loss\n",
    "  def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = objectives.categorical_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    xent_loss = K.sum(xent_loss, axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "  autoencoder.compile(loss=vae_loss, optimizer=\"adam\", metrics=['categorical_accuracy'], experimental_run_tf_function=False)\n",
    "  return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4051,
     "status": "ok",
     "timestamp": 1620978943991,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 420
    },
    "id": "riDg3q0xgkpB",
    "outputId": "e2349c93-9365-44b1-a5a1-14fe104d8a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"Encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(10, 22, 71)]            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (10, 22, 32)              11264     \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (10, 22, 20)              3440      \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (10, 12)                  1296      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (10, 6)                   78        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (10, 6)                   42        \n",
      "=================================================================\n",
      "Total params: 16,120\n",
      "Trainable params: 16,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto multiple                  0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection multiple                  1360      \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection multiple                  4736      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist multiple                  2343      \n",
      "=================================================================\n",
      "Total params: 8,439\n",
      "Trainable params: 8,439\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "variational_encoder, variational_decoder, variational_autoencoder = create_lstm_vae(PASS_LENGTH, [16, 10, 6], vocab_size)\n",
    "variational_encoder.summary()\n",
    "variational_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "executionInfo": {
     "elapsed": 1707214,
     "status": "error",
     "timestamp": 1620980655201,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 420
    },
    "id": "wMqbhT7V4Is_",
    "outputId": "1336767a-0711-458b-a71e-b4ed5089fa5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15540 samples\n",
      "Epoch 1/200\n",
      "15540/15540 [==============================] - 241s 15ms/sample - loss: 49.5768 - categorical_accuracy: 0.4006\n",
      "Epoch 2/200\n",
      "15540/15540 [==============================] - 234s 15ms/sample - loss: 41.7288 - categorical_accuracy: 0.4303\n",
      "Epoch 3/200\n",
      "15540/15540 [==============================] - 234s 15ms/sample - loss: 40.6454 - categorical_accuracy: 0.4342\n",
      "Epoch 4/200\n",
      "15540/15540 [==============================] - 233s 15ms/sample - loss: 40.0937 - categorical_accuracy: 0.4356\n",
      "Epoch 5/200\n",
      "15540/15540 [==============================] - 230s 15ms/sample - loss: 39.8015 - categorical_accuracy: 0.4357\n",
      "Epoch 6/200\n",
      "15540/15540 [==============================] - 230s 15ms/sample - loss: 39.5886 - categorical_accuracy: 0.4362\n",
      "Epoch 7/200\n",
      "15540/15540 [==============================] - 232s 15ms/sample - loss: 39.5213 - categorical_accuracy: 0.4362\n",
      "Epoch 8/200\n",
      " 4560/15540 [=======>......................] - ETA: 2:42 - loss: 39.5656 - categorical_accuracy: 0.4361"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b603c3e3a9d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvariational_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3956\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3957\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3958\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3959\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "variational_autoencoder.fit(one_hot_encoded, one_hot_encoded, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3343519,
     "status": "ok",
     "timestamp": 1620280938756,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "Tr0yx6JW432-",
    "outputId": "63903346-78a3-452d-c7f2-9931464fd26c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "# Recosntruct passwords through autoencoder as vectors\n",
    "reconst_passwd_vecs = variational_autoencoder.predict(one_hot_encoded, batch_size=10)\n",
    "# Reverse one hot encoding to covnert passwords to strings\n",
    "unpad = lambda text: text.replace(PAD_CHAR, \"\")\n",
    "one_hot_decode = lambda one_hot_vectors: \"\".join([list(charset)[np.argmax(vec)] for vec in one_hot_vectors])\n",
    "reconst_passwd_str = [unpad(one_hot_decode(p)) for p in reconst_passwd_vecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 3343518,
     "status": "ok",
     "timestamp": 1620280938764,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "uoD_CrqLrtJa",
    "outputId": "a55f24d2-0f76-42d6-cb89-84722a7fd7dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Password</th>\n",
       "      <th>Recosntructed Password</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acafe2019!</td>\n",
       "      <td>Acafe2019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahyper2019!</td>\n",
       "      <td>Ahyper2019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pleet10!</td>\n",
       "      <td>Aleet10!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ababe2!</td>\n",
       "      <td>Ababe1!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tbingo1234*</td>\n",
       "      <td>Abingo1234!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eleet2019@</td>\n",
       "      <td>Aleet2019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tninja123!</td>\n",
       "      <td>Aninja1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aninja777*</td>\n",
       "      <td>Aninja123*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ababe101*</td>\n",
       "      <td>Ababe111!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tbingo2019_</td>\n",
       "      <td>Abingo2019!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Original Password Recosntructed Password\n",
       "0        Acafe2019!             Acafe2019!\n",
       "1       Ahyper2019!            Ahyper2019!\n",
       "2          Pleet10!               Aleet10!\n",
       "3           Ababe2!                Ababe1!\n",
       "4       Tbingo1234*            Abingo1234!\n",
       "5        Eleet2019@             Aleet2019!\n",
       "6        Tninja123!             Aninja1234\n",
       "7        Aninja777*             Aninja123*\n",
       "8         Ababe101*              Ababe111!\n",
       "9       Tbingo2019_            Abingo2019!"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare original vs reconstructed passwords\n",
    "passwords_df = pd.DataFrame(zip(passwords[\"FullPassword\"], reconst_passwd_str),\n",
    "                            columns = ['Original Password', 'Recosntructed Password'])\n",
    "passwords_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new passwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "executionInfo": {
     "elapsed": 3345739,
     "status": "ok",
     "timestamp": 1620280940995,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "bKjsoUoRsEsy",
    "outputId": "aa03befa-38ec-4f78-efd1-9837b7ab5974"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Password</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ababe2!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tleet2!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAyceemannn27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aleet0019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahabe2!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abingg201!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abingo1219!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ahackerm1n2019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abigo1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abingo111!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Password\n",
       "0          Ababe2!\n",
       "1          Tleet2!\n",
       "2    AAyceemannn27\n",
       "3       Aleet0019!\n",
       "4          Ahabe2!\n",
       "5       Abingg201!\n",
       "6      Abingo1219!\n",
       "7  Ahackerm1n2019!\n",
       "8           Abigo1\n",
       "9       Abingo111!"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Feel free to change the latent space values as you like and explore what comes\n",
    "# out from the decoder\n",
    "mu, sigma = 0, 3\n",
    "new_passwords = []\n",
    "for i in range(100):\n",
    "  latent_sample = np.array([np.random.normal(mu, sigma, 6)])\n",
    "  new_password_vec = variational_decoder.predict(latent_sample)\n",
    "  new_password_str = unpad(one_hot_decode(new_password_vec[0]))\n",
    "  new_passwords.append(new_password_str)\n",
    "new_passwords_df = pd.DataFrame(new_passwords, columns=[\"Password\"])\n",
    "\n",
    "# Save them into a CSV file\n",
    "new_passwords_df.to_csv(path + 'data/output/vae_sample_pass.csv', sep=',')\n",
    "\n",
    "new_passwords_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcualte the Average Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3543,
     "status": "ok",
     "timestamp": 1620282164205,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "SkcY1E10B9eD",
    "outputId": "050f2705-fb18-4e4b-88ee-f241a5abed65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: BiEntropy in /usr/local/lib/python3.7/dist-packages (1.1.4)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from BiEntropy) (1.19.5)\n",
      "Requirement already satisfied: bitstring>=3.1.5 in /usr/local/lib/python3.7/dist-packages (from BiEntropy) (3.1.7)\n",
      "MAX entropy: 0.9720206778899985\n",
      "MIN entropy: 0.04472879972300151\n",
      "AVG entropy: 0.9135753011113651\n"
     ]
    }
   ],
   "source": [
    "!pip install BiEntropy\n",
    "\n",
    "from bientropy import bien, tbien\n",
    "\n",
    "sum_entropy = 0\n",
    "max_entropy = float('-inf')\n",
    "min_entropy = float('inf')\n",
    "\n",
    "for pswd in new_passwords:\n",
    "  pswd_bytes = bytes(pswd, 'utf-8')\n",
    "  e = tbien(pswd_bytes)\n",
    "  sum_entropy += e\n",
    "  # update the max and the min entropy\n",
    "  max_entropy = max(max_entropy, e)\n",
    "  min_entropy = min(min_entropy, e)\n",
    "\n",
    "avg_entropy = sum_entropy / len(new_passwords)\n",
    "\n",
    "print(\"MAX entropy: \" + str(max_entropy))\n",
    "print(\"MIN entropy: \" + str(min_entropy))\n",
    "print(\"AVG entropy: \" + str(avg_entropy))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "15kPass_Variational_Autoencoder_Generating_Passwords.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
