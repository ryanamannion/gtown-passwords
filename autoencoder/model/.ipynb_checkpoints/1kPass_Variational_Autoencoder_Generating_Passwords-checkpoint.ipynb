{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31478,
     "status": "ok",
     "timestamp": 1620277626679,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "hPZ1jrOMhqZa",
    "outputId": "552baad4-3de3-4fa6-f2ef-7ca265d31bd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "    Capital   Word Numeric Special FullPassword\n",
      "0         A   cafe    2019       !   Acafe2019!\n",
      "1         A  hyper    2019       !  Ahyper2019!\n",
      "2         P   leet      10       !     Pleet10!\n",
      "3         A   babe       2       !      Ababe2!\n",
      "4         T  bingo    1234       *  Tbingo1234*\n",
      "..      ...    ...     ...     ...          ...\n",
      "995       A   leet     123       !    Aleet123!\n",
      "996       A  hyper     777       !   Ahyper777!\n",
      "997       P   cafe     123       *    Pcafe123*\n",
      "998       A   cafe      10       %     Acafe10%\n",
      "999       A   babe     101       _    Ababe101_\n",
      "\n",
      "[1000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "path = \"/content/drive/MyDrive/gtown-passwords/autoencoder/\"\n",
    "\n",
    "passwords = pd.read_csv(path + \"data/1000passwords.csv\", dtype={'Numeric': str})\n",
    "print(passwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot Character Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hQpuqedCmCK"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Identify max password length in dataset and pad rest of the passwords such that all of them have the same length.\n",
    "# Haveing same length sequences is a requirement for LSTM\n",
    "PAD_CHAR = \"~\"\n",
    "PASS_LENGTH = max([len(p) for p in passwords[\"FullPassword\"]])\n",
    "\n",
    "padded_passwords = []\n",
    "charset = set(PAD_CHAR)               # start with the initial padding char\n",
    "for p in passwords[\"FullPassword\"]:\n",
    "  padded_passwords.append(p.ljust(PASS_LENGTH, PAD_CHAR))\n",
    "  charset |= set(p)                   # |= is the union set operation.\n",
    "\n",
    "# Convert characters to integers \n",
    "vocab_size = len(charset)\n",
    "char2id = dict((c, i) for i, c in enumerate(charset))\n",
    "\n",
    "# One hot encode the passwords\n",
    "encoded_passwords = [[char2id[c] for c in password] for password in padded_passwords]\n",
    "one_hot_encoded = np.array([to_categorical(p, num_classes=vocab_size) for p in encoded_passwords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCuhe7txgiaQ"
   },
   "source": [
    "Variational Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozdw0mcxBiK2"
   },
   "outputs": [],
   "source": [
    "from keras import objectives\n",
    "from keras import backend as K\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input, Lambda, Layer, Bidirectional\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "\n",
    "def create_lstm_vae(timesteps, layer_sizes, vocab_size, epsilon_std=1.,\n",
    "                    batch_size=10):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(layer_sizes[-1],),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(.5 * z_log_sigma) * epsilon\n",
    "  \n",
    "  # Create encoder model\n",
    "  enc_input = Input(batch_shape=(batch_size, timesteps, vocab_size))\n",
    "  x = enc_input\n",
    "  for idx, layer_size in enumerate(layer_sizes):\n",
    "    ret_seq = (idx != len(layer_sizes) - 1) # False for the last layer_size\n",
    "    x = Bidirectional(LSTM(layer_size, return_sequences=ret_seq))(x)\n",
    "  enc_output = Dense(layer_sizes[-1], activation=\"relu\")(x)\n",
    "  z_mean = Dense(layer_sizes[-1])(enc_output)\n",
    "  z_log_sigma = Dense(layer_sizes[-1])(enc_output)\n",
    "  z = Lambda(sampling, output_shape=(layer_sizes[-1],))([z_mean, z_log_sigma])\n",
    "  encoder = Model(enc_input, z_mean, name=\"Encoder\")\n",
    "\n",
    "  # Create decoder model\n",
    "  bottleneck_size = layer_sizes[-1]\n",
    "  dec_input = Input((bottleneck_size,))\n",
    "  layer = RepeatVector(timesteps)\n",
    "  x = layer(z)\n",
    "  _x = layer(dec_input)\n",
    "  for layer_size in layer_sizes[::-1][1:]:\n",
    "    layer = Bidirectional(LSTM(layer_size, return_sequences=True))\n",
    "    x = layer(x)\n",
    "    _x = layer(_x)\n",
    "  layer =  TimeDistributed(Dense(vocab_size, activation=\"softmax\"))\n",
    "  dec_output = layer(x)\n",
    "  _dec_output = layer(_x)\n",
    "  decoder = Model(dec_input, _dec_output, name=\"Decoder\")\n",
    "\n",
    "  # connected_decoder = decoder(z_mean)\n",
    "\n",
    "  # Create autoencoder model\n",
    "  autoencoder = Model(enc_input, dec_output, name=\"Autoencoder\")\n",
    "  # autoencoder = Model(enc_input, connected_decoder, name=\"Autoencoder\")\n",
    "\n",
    "  # Variational autoencoder custom loss categorical entropy loss + KL loss\n",
    "  def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = objectives.categorical_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    xent_loss = K.sum(xent_loss, axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "  autoencoder.compile(loss=vae_loss, optimizer=\"adam\", metrics=['categorical_accuracy'], experimental_run_tf_function=False)\n",
    "  return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41285,
     "status": "ok",
     "timestamp": 1620277636503,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "riDg3q0xgkpB",
    "outputId": "44dc286d-6fdc-4bee-d503-3b0772f12342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"Encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(10, 15, 38)]            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (10, 15, 32)              7040      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (10, 15, 20)              3440      \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (10, 12)                  1296      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (10, 6)                   78        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (10, 6)                   42        \n",
      "=================================================================\n",
      "Total params: 11,896\n",
      "Trainable params: 11,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) multiple                  0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection multiple                  1360      \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection multiple                  4736      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri multiple                  1254      \n",
      "=================================================================\n",
      "Total params: 7,350\n",
      "Trainable params: 7,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "variational_encoder, variational_decoder, variational_autoencoder = create_lstm_vae(PASS_LENGTH, [16, 10, 6], vocab_size)\n",
    "variational_encoder.summary()\n",
    "variational_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3340382,
     "status": "ok",
     "timestamp": 1620280935610,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "wMqbhT7V4Is_",
    "outputId": "0442848f-a8de-4e85-ffa5-eeebd26b77fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/300\n",
      "1000/1000 [==============================] - 14s 14ms/sample - loss: 50.5882 - categorical_accuracy: 0.2289\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 38.8901 - categorical_accuracy: 0.3433\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 34.5808 - categorical_accuracy: 0.4034\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 32.1044 - categorical_accuracy: 0.4296\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 29.9580 - categorical_accuracy: 0.4602\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 28.1702 - categorical_accuracy: 0.4737\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 26.8165 - categorical_accuracy: 0.4763\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 25.8125 - categorical_accuracy: 0.4791\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 24.8576 - categorical_accuracy: 0.4830\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 23.9371 - categorical_accuracy: 0.4974\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 23.3805 - categorical_accuracy: 0.5061\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 22.6710 - categorical_accuracy: 0.5311\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 21.9280 - categorical_accuracy: 0.5393\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 21.3636 - categorical_accuracy: 0.5449\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 20.5878 - categorical_accuracy: 0.5601\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 20.1172 - categorical_accuracy: 0.5649\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 19.5042 - categorical_accuracy: 0.5745\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 19.0731 - categorical_accuracy: 0.5787\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 18.6691 - categorical_accuracy: 0.5866\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 18.3160 - categorical_accuracy: 0.5931\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 17.6741 - categorical_accuracy: 0.6057\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 17.4223 - categorical_accuracy: 0.6140\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 17.1822 - categorical_accuracy: 0.6185\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 16.7300 - categorical_accuracy: 0.6333\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 16.4695 - categorical_accuracy: 0.6446\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 15.9926 - categorical_accuracy: 0.6552\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 15.5448 - categorical_accuracy: 0.6641\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 15.4325 - categorical_accuracy: 0.6659\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 15.2254 - categorical_accuracy: 0.6703\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 14.8568 - categorical_accuracy: 0.6758\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 14.3937 - categorical_accuracy: 0.6839\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 14.2293 - categorical_accuracy: 0.6797\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 14.1145 - categorical_accuracy: 0.6845\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 14.0498 - categorical_accuracy: 0.6853\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 13.6708 - categorical_accuracy: 0.6892\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 13.5234 - categorical_accuracy: 0.6918\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 13.4714 - categorical_accuracy: 0.6931\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 13.1601 - categorical_accuracy: 0.6963\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 13.3050 - categorical_accuracy: 0.6924\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 13.0704 - categorical_accuracy: 0.6958\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.8109 - categorical_accuracy: 0.7081\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.7431 - categorical_accuracy: 0.7007\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.6471 - categorical_accuracy: 0.7029\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.5594 - categorical_accuracy: 0.7046\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.3564 - categorical_accuracy: 0.7101\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.5463 - categorical_accuracy: 0.7039\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.3837 - categorical_accuracy: 0.7014\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.3036 - categorical_accuracy: 0.7085\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.0650 - categorical_accuracy: 0.7138\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.0776 - categorical_accuracy: 0.7137\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.1314 - categorical_accuracy: 0.7102\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.2208 - categorical_accuracy: 0.7023\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.0660 - categorical_accuracy: 0.7119\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 12.0231 - categorical_accuracy: 0.7181\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 11.8911 - categorical_accuracy: 0.7229\n",
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 11.7595 - categorical_accuracy: 0.7279\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 11.5588 - categorical_accuracy: 0.7379\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 11.5051 - categorical_accuracy: 0.7405\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 11.4182 - categorical_accuracy: 0.7516\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 11.1297 - categorical_accuracy: 0.7612\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 11.0377 - categorical_accuracy: 0.7654\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 10.7722 - categorical_accuracy: 0.7709\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 10.5557 - categorical_accuracy: 0.7785\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 10.9359 - categorical_accuracy: 0.7624\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 10.4991 - categorical_accuracy: 0.7745\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 10.2636 - categorical_accuracy: 0.7802\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 10.0638 - categorical_accuracy: 0.7846\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 10.1109 - categorical_accuracy: 0.7815\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 10.0868 - categorical_accuracy: 0.7809\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.8860 - categorical_accuracy: 0.7838\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.8471 - categorical_accuracy: 0.7835\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.8304 - categorical_accuracy: 0.7848\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.7167 - categorical_accuracy: 0.7855\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.7640 - categorical_accuracy: 0.7840\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 10.1690 - categorical_accuracy: 0.7759\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.7668 - categorical_accuracy: 0.7836\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.6289 - categorical_accuracy: 0.7867\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.5107 - categorical_accuracy: 0.7863\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.5360 - categorical_accuracy: 0.7863\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.7262 - categorical_accuracy: 0.7835\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.4180 - categorical_accuracy: 0.7892\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.3266 - categorical_accuracy: 0.7918\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.2704 - categorical_accuracy: 0.7920\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.5615 - categorical_accuracy: 0.7838\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.6391 - categorical_accuracy: 0.7853\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.3218 - categorical_accuracy: 0.7924\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.1763 - categorical_accuracy: 0.7936\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.3298 - categorical_accuracy: 0.7943\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.2539 - categorical_accuracy: 0.7919\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.1128 - categorical_accuracy: 0.7943\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.1655 - categorical_accuracy: 0.7932\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.1021 - categorical_accuracy: 0.7973\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.0439 - categorical_accuracy: 0.7969\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.9018 - categorical_accuracy: 0.7999\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.8253 - categorical_accuracy: 0.8032\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.8699 - categorical_accuracy: 0.7995\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.2557 - categorical_accuracy: 0.7967\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.9820 - categorical_accuracy: 0.7989\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.7131 - categorical_accuracy: 0.8069\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.5913 - categorical_accuracy: 0.8071\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.6713 - categorical_accuracy: 0.8051\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.7132 - categorical_accuracy: 0.8066\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.1560 - categorical_accuracy: 0.7978\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.6582 - categorical_accuracy: 0.7820\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.7183 - categorical_accuracy: 0.8064\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.6141 - categorical_accuracy: 0.8076\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.4571 - categorical_accuracy: 0.8136\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.4425 - categorical_accuracy: 0.8117\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.4672 - categorical_accuracy: 0.8128\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.3392 - categorical_accuracy: 0.8143\n",
      "Epoch 111/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.3856 - categorical_accuracy: 0.8170\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.2889 - categorical_accuracy: 0.8207\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.1926 - categorical_accuracy: 0.8230\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.1242 - categorical_accuracy: 0.8249\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.0682 - categorical_accuracy: 0.8267\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.2683 - categorical_accuracy: 0.8240\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.1402 - categorical_accuracy: 0.8269\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.1054 - categorical_accuracy: 0.8262\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.9437 - categorical_accuracy: 0.8298\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.9114 - categorical_accuracy: 0.8306\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.1139 - categorical_accuracy: 0.8042\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.9871 - categorical_accuracy: 0.8042\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.1798 - categorical_accuracy: 0.8282\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.9951 - categorical_accuracy: 0.8320\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.9796 - categorical_accuracy: 0.8308\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.8684 - categorical_accuracy: 0.8328\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.8789 - categorical_accuracy: 0.8335\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.8432 - categorical_accuracy: 0.8327\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.1116 - categorical_accuracy: 0.8307\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.9499 - categorical_accuracy: 0.8286\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.6171 - categorical_accuracy: 0.8362\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.6022 - categorical_accuracy: 0.8364\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.5745 - categorical_accuracy: 0.8385\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.7074 - categorical_accuracy: 0.8367\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.6419 - categorical_accuracy: 0.8383\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.5009 - categorical_accuracy: 0.8395\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.4492 - categorical_accuracy: 0.8407\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.5172 - categorical_accuracy: 0.8013\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.7298 - categorical_accuracy: 0.8368\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.4563 - categorical_accuracy: 0.8409\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.4619 - categorical_accuracy: 0.8423\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.2489 - categorical_accuracy: 0.8453\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.3690 - categorical_accuracy: 0.8406\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.3340 - categorical_accuracy: 0.8449\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.1607 - categorical_accuracy: 0.8486\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.1778 - categorical_accuracy: 0.8474\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.0981 - categorical_accuracy: 0.8467\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.0019 - categorical_accuracy: 0.8505\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.3407 - categorical_accuracy: 0.8409\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.0460 - categorical_accuracy: 0.8496\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.9430 - categorical_accuracy: 0.8525\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.9708 - categorical_accuracy: 0.8521\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.9377 - categorical_accuracy: 0.8532\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.9826 - categorical_accuracy: 0.8515\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.0488 - categorical_accuracy: 0.8493\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.8424 - categorical_accuracy: 0.8542\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.4705 - categorical_accuracy: 0.8473\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.9269 - categorical_accuracy: 0.8547\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.9274 - categorical_accuracy: 0.8528\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.8562 - categorical_accuracy: 0.8552\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.2856 - categorical_accuracy: 0.8466\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.9494 - categorical_accuracy: 0.8555\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.8176 - categorical_accuracy: 0.8573\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 9.2822 - categorical_accuracy: 0.8075\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.1373 - categorical_accuracy: 0.8520\n",
      "Epoch 166/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.8175 - categorical_accuracy: 0.8576\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.8036 - categorical_accuracy: 0.8584\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.7706 - categorical_accuracy: 0.8581\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.3945 - categorical_accuracy: 0.8403\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.9556 - categorical_accuracy: 0.8562\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.7092 - categorical_accuracy: 0.8595\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.8340 - categorical_accuracy: 0.8592\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.7674 - categorical_accuracy: 0.8563\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.6855 - categorical_accuracy: 0.8589\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.9663 - categorical_accuracy: 0.8349\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.7996 - categorical_accuracy: 0.8590\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.7870 - categorical_accuracy: 0.8607\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.6028 - categorical_accuracy: 0.8633\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.5483 - categorical_accuracy: 0.8661\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.6058 - categorical_accuracy: 0.8633\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.8248 - categorical_accuracy: 0.8570\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.4549 - categorical_accuracy: 0.8653\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.6274 - categorical_accuracy: 0.8615\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.5015 - categorical_accuracy: 0.8636\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.4100 - categorical_accuracy: 0.8671\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.3474 - categorical_accuracy: 0.8667\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.4368 - categorical_accuracy: 0.8633\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.4475 - categorical_accuracy: 0.8645\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.2741 - categorical_accuracy: 0.8675\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 6.4304 - categorical_accuracy: 0.8657\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 6.2586 - categorical_accuracy: 0.8673\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 6.7052 - categorical_accuracy: 0.8591\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 6.3209 - categorical_accuracy: 0.8662\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 6.2564 - categorical_accuracy: 0.8696\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 6.2518 - categorical_accuracy: 0.8679\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 6.2359 - categorical_accuracy: 0.8661\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.1137 - categorical_accuracy: 0.8723\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.1675 - categorical_accuracy: 0.8697\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 6.1754 - categorical_accuracy: 0.8691\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.0522 - categorical_accuracy: 0.8710\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 6.1865 - categorical_accuracy: 0.8689\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.0821 - categorical_accuracy: 0.8708\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.1943 - categorical_accuracy: 0.8688\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 6.1543 - categorical_accuracy: 0.8709\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.9596 - categorical_accuracy: 0.8742\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.1718 - categorical_accuracy: 0.8709\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.1755 - categorical_accuracy: 0.8690\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.0076 - categorical_accuracy: 0.8734\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.7597 - categorical_accuracy: 0.8573\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.5703 - categorical_accuracy: 0.8611\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.0181 - categorical_accuracy: 0.8740\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.3152 - categorical_accuracy: 0.8692\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.1137 - categorical_accuracy: 0.8746\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.9062 - categorical_accuracy: 0.8747\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.1171 - categorical_accuracy: 0.8709\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.1182 - categorical_accuracy: 0.8722\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.9596 - categorical_accuracy: 0.8719\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.6176 - categorical_accuracy: 0.8623\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.2722 - categorical_accuracy: 0.8683\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.9178 - categorical_accuracy: 0.8789\n",
      "Epoch 221/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8446 - categorical_accuracy: 0.8773\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8133 - categorical_accuracy: 0.8783\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8231 - categorical_accuracy: 0.8757\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.9140 - categorical_accuracy: 0.8756\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8565 - categorical_accuracy: 0.8769\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8056 - categorical_accuracy: 0.8794\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8060 - categorical_accuracy: 0.8768\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.9158 - categorical_accuracy: 0.8733\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8905 - categorical_accuracy: 0.8754\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8387 - categorical_accuracy: 0.8781\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 5.7139 - categorical_accuracy: 0.8797\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 5.6854 - categorical_accuracy: 0.8818\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.7463 - categorical_accuracy: 0.8789\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.6648 - categorical_accuracy: 0.8805\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 5.9693 - categorical_accuracy: 0.8765\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.6924 - categorical_accuracy: 0.8812\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 5.5443 - categorical_accuracy: 0.8851\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 5.8479 - categorical_accuracy: 0.8769\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.1386 - categorical_accuracy: 0.8587\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.1284 - categorical_accuracy: 0.8688\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8686 - categorical_accuracy: 0.8756\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8959 - categorical_accuracy: 0.8772\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.0743 - categorical_accuracy: 0.8489\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8343 - categorical_accuracy: 0.8807\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.5681 - categorical_accuracy: 0.8875\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.5684 - categorical_accuracy: 0.8858\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 5.6545 - categorical_accuracy: 0.8811\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.5105 - categorical_accuracy: 0.8877\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.5829 - categorical_accuracy: 0.8849\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.5396 - categorical_accuracy: 0.8865\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.5959 - categorical_accuracy: 0.8824\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.6156 - categorical_accuracy: 0.8826\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.5403 - categorical_accuracy: 0.8841\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 5.3781 - categorical_accuracy: 0.8883\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.3891 - categorical_accuracy: 0.8869\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.3473 - categorical_accuracy: 0.8881\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.5405 - categorical_accuracy: 0.8827\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 13.1886 - categorical_accuracy: 0.7777\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 8.1413 - categorical_accuracy: 0.8326\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.4092 - categorical_accuracy: 0.8486\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.0703 - categorical_accuracy: 0.8562\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.8645 - categorical_accuracy: 0.8587\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 7.0453 - categorical_accuracy: 0.8589\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.7019 - categorical_accuracy: 0.8619\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 6.7883 - categorical_accuracy: 0.8620\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 12s 12ms/sample - loss: 6.6734 - categorical_accuracy: 0.8636\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.4156 - categorical_accuracy: 0.8673\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.3493 - categorical_accuracy: 0.8680\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.2694 - categorical_accuracy: 0.8712\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.2476 - categorical_accuracy: 0.8699\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.1127 - categorical_accuracy: 0.8722\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.1143 - categorical_accuracy: 0.8747\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.0429 - categorical_accuracy: 0.8760\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.9424 - categorical_accuracy: 0.8775\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.9788 - categorical_accuracy: 0.8767\n",
      "Epoch 276/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8957 - categorical_accuracy: 0.8781\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8202 - categorical_accuracy: 0.8793\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.7538 - categorical_accuracy: 0.8827\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.7190 - categorical_accuracy: 0.8843\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.0272 - categorical_accuracy: 0.8767\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.8049 - categorical_accuracy: 0.8807\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 5.7164 - categorical_accuracy: 0.8835\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 5.7202 - categorical_accuracy: 0.8833\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.6656 - categorical_accuracy: 0.8839\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.7745 - categorical_accuracy: 0.8814\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.6251 - categorical_accuracy: 0.8846\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.6256 - categorical_accuracy: 0.8845\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.6424 - categorical_accuracy: 0.8833\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 5.6073 - categorical_accuracy: 0.8839\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.5164 - categorical_accuracy: 0.8876\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.5147 - categorical_accuracy: 0.8861\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 5.5560 - categorical_accuracy: 0.8869\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.5209 - categorical_accuracy: 0.8871\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.7980 - categorical_accuracy: 0.8797\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.4687 - categorical_accuracy: 0.8891\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.4474 - categorical_accuracy: 0.8671\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 6.3909 - categorical_accuracy: 0.8678\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 5.8571 - categorical_accuracy: 0.8799\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 10s 10ms/sample - loss: 5.7121 - categorical_accuracy: 0.8835\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 11s 11ms/sample - loss: 5.7184 - categorical_accuracy: 0.8837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2f266b8d10>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variational_autoencoder.fit(one_hot_encoded, one_hot_encoded, epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3343519,
     "status": "ok",
     "timestamp": 1620280938756,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "Tr0yx6JW432-",
    "outputId": "63903346-78a3-452d-c7f2-9931464fd26c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "# Recosntruct passwords through autoencoder as vectors\n",
    "reconst_passwd_vecs = variational_autoencoder.predict(one_hot_encoded, batch_size=10)\n",
    "# Reverse one hot encoding to covnert passwords to strings\n",
    "unpad = lambda text: text.replace(PAD_CHAR, \"\")\n",
    "one_hot_decode = lambda one_hot_vectors: \"\".join([list(charset)[np.argmax(vec)] for vec in one_hot_vectors])\n",
    "reconst_passwd_str = [unpad(one_hot_decode(p)) for p in reconst_passwd_vecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 3343518,
     "status": "ok",
     "timestamp": 1620280938764,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "uoD_CrqLrtJa",
    "outputId": "a55f24d2-0f76-42d6-cb89-84722a7fd7dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Password</th>\n",
       "      <th>Recosntructed Password</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acafe2019!</td>\n",
       "      <td>Acafe2019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahyper2019!</td>\n",
       "      <td>Ahyper2019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pleet10!</td>\n",
       "      <td>Aleet10!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ababe2!</td>\n",
       "      <td>Ababe1!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tbingo1234*</td>\n",
       "      <td>Abingo1234!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eleet2019@</td>\n",
       "      <td>Aleet2019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tninja123!</td>\n",
       "      <td>Aninja1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aninja777*</td>\n",
       "      <td>Aninja123*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ababe101*</td>\n",
       "      <td>Ababe111!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tbingo2019_</td>\n",
       "      <td>Abingo2019!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Original Password Recosntructed Password\n",
       "0        Acafe2019!             Acafe2019!\n",
       "1       Ahyper2019!            Ahyper2019!\n",
       "2          Pleet10!               Aleet10!\n",
       "3           Ababe2!                Ababe1!\n",
       "4       Tbingo1234*            Abingo1234!\n",
       "5        Eleet2019@             Aleet2019!\n",
       "6        Tninja123!             Aninja1234\n",
       "7        Aninja777*             Aninja123*\n",
       "8         Ababe101*              Ababe111!\n",
       "9       Tbingo2019_            Abingo2019!"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare original vs reconstructed passwords\n",
    "passwords_df = pd.DataFrame(zip(passwords[\"FullPassword\"], reconst_passwd_str),\n",
    "                            columns = ['Original Password', 'Recosntructed Password'])\n",
    "passwords_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new passwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "executionInfo": {
     "elapsed": 3345739,
     "status": "ok",
     "timestamp": 1620280940995,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "bKjsoUoRsEsy",
    "outputId": "aa03befa-38ec-4f78-efd1-9837b7ab5974"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Password</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ababe2!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tleet2!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAyceemannn27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aleet0019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahabe2!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abingg201!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abingo1219!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ahackerm1n2019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abigo1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abingo111!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Password\n",
       "0          Ababe2!\n",
       "1          Tleet2!\n",
       "2    AAyceemannn27\n",
       "3       Aleet0019!\n",
       "4          Ahabe2!\n",
       "5       Abingg201!\n",
       "6      Abingo1219!\n",
       "7  Ahackerm1n2019!\n",
       "8           Abigo1\n",
       "9       Abingo111!"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Feel free to change the latent space values as you like and explore what comes\n",
    "# out from the decoder\n",
    "mu, sigma = 0, 3\n",
    "new_passwords = []\n",
    "for i in range(100):\n",
    "  latent_sample = np.array([np.random.normal(mu, sigma, 6)])\n",
    "  new_password_vec = variational_decoder.predict(latent_sample)\n",
    "  new_password_str = unpad(one_hot_decode(new_password_vec[0]))\n",
    "  new_passwords.append(new_password_str)\n",
    "new_passwords_df = pd.DataFrame(new_passwords, columns=[\"Password\"])\n",
    "\n",
    "# Save them into a CSV file\n",
    "new_passwords_df.to_csv(path + 'data/output/vae_sample_pass.csv', sep=',')\n",
    "\n",
    "new_passwords_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcualte the Average Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3543,
     "status": "ok",
     "timestamp": 1620282164205,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "SkcY1E10B9eD",
    "outputId": "050f2705-fb18-4e4b-88ee-f241a5abed65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: BiEntropy in /usr/local/lib/python3.7/dist-packages (1.1.4)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from BiEntropy) (1.19.5)\n",
      "Requirement already satisfied: bitstring>=3.1.5 in /usr/local/lib/python3.7/dist-packages (from BiEntropy) (3.1.7)\n",
      "MAX entropy: 0.9720206778899985\n",
      "MIN entropy: 0.04472879972300151\n",
      "AVG entropy: 0.9135753011113651\n"
     ]
    }
   ],
   "source": [
    "!pip install BiEntropy\n",
    "\n",
    "from bientropy import bien, tbien\n",
    "\n",
    "sum_entropy = 0\n",
    "max_entropy = float('-inf')\n",
    "min_entropy = float('inf')\n",
    "\n",
    "for pswd in new_passwords:\n",
    "  pswd_bytes = bytes(pswd, 'utf-8')\n",
    "  e = tbien(pswd_bytes)\n",
    "  sum_entropy += e\n",
    "  # update the max and the min entropy\n",
    "  max_entropy = max(max_entropy, e)\n",
    "  min_entropy = min(min_entropy, e)\n",
    "\n",
    "avg_entropy = sum_entropy / len(new_passwords)\n",
    "\n",
    "print(\"MAX entropy: \" + str(max_entropy))\n",
    "print(\"MIN entropy: \" + str(min_entropy))\n",
    "print(\"AVG entropy: \" + str(avg_entropy))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Variational_Autoencoder_Generating_Passwords.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
