{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCXOG5gA94tL"
   },
   "source": [
    "# The Autoencoder Trained on GU Passphrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrubbed.Frigidly.Viral.Cushy.Overlap\n",
      "Extinct.Reach.Tactless.Chafe.Flashbulb\n",
      "Certified@Surrender@Senior@Amperage@Oops\n",
      "Shrug!Seminar!Enroll!Hankering!Detract\n",
      "Diminish!Sedate!Pulsate!Steersman!Caretaker\n",
      "pulverize!unbolted!comrade!humorist!humvee\n",
      "Banked@Payment@Velcro@Spoon@Wimp\n",
      "bonnet@improper@many@variable@prelaunch\n",
      "Frosted@Paycheck@Spree@Runny@Debunk\n",
      "poker!rippling!irregular!nuclear!unexpired\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "path = \"/content/drive/MyDrive/gtown-passwords/autoencoder/\"\n",
    "\n",
    "passwords = []\n",
    "\n",
    "with open(\"/content/drive/MyDrive/gtown-passwords/baseline/examples/baseline_complex.txt\", encoding='utf-8') as f:\n",
    "    readlines = f.readlines()\n",
    "    for line in readlines:\n",
    "        passwords.append(line.strip())\n",
    "\n",
    "for i in range(10):\n",
    "    print(passwords[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot Character Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1836,
     "status": "ok",
     "timestamp": 1620980782391,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 420
    },
    "id": "7hQpuqedCmCK",
    "outputId": "5520f08b-29f4-4ea5-b311-1a7de10a3fd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "56\n",
      "(1000, 49)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Identify max password length in dataset and pad rest of the passwords such that all of them have the same length.\n",
    "# Haveing same length sequences is a requirement for LSTM\n",
    "PAD_CHAR = \"~\"\n",
    "PASS_LENGTH = max([len(p) for p in passwords])\n",
    "\n",
    "padded_passwords = []\n",
    "charset = set(PAD_CHAR)               # start with the initial padding char\n",
    "for p in passwords:\n",
    "  padded_passwords.append(p.ljust(PASS_LENGTH, PAD_CHAR))\n",
    "  charset |= set(p)                   # |= is the union set operation.\n",
    "\n",
    "# Convert characters to integers \n",
    "vocab_size = len(charset)\n",
    "char2id = dict((c, i) for i, c in enumerate(charset))\n",
    "\n",
    "# One hot encode the passwords\n",
    "encoded_passwords = [[char2id[c] for c in password] for password in padded_passwords]\n",
    "one_hot_encoded = np.array([to_categorical(p, num_classes=vocab_size) for p in encoded_passwords])\n",
    "\n",
    "print(PASS_LENGTH)\n",
    "print(vocab_size)\n",
    "print(np.shape(encoded_passwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCuhe7txgiaQ"
   },
   "source": [
    "Variational Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1620980789607,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 420
    },
    "id": "ozdw0mcxBiK2"
   },
   "outputs": [],
   "source": [
    "from keras import objectives\n",
    "from keras import backend as K\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input, Lambda, Layer, Bidirectional\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "\n",
    "def create_lstm_vae(timesteps, layer_sizes, vocab_size, epsilon_std=1.,\n",
    "                    batch_size=10):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(layer_sizes[-1],),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(.5 * z_log_sigma) * epsilon\n",
    "  \n",
    "  # Create encoder model\n",
    "  enc_input = Input(batch_shape=(batch_size, timesteps, vocab_size))\n",
    "  x = enc_input\n",
    "  for idx, layer_size in enumerate(layer_sizes):\n",
    "    ret_seq = (idx != len(layer_sizes) - 1) # False for the last layer_size\n",
    "    x = Bidirectional(LSTM(layer_size, return_sequences=ret_seq))(x)\n",
    "  enc_output = Dense(layer_sizes[-1], activation=\"relu\")(x)\n",
    "  z_mean = Dense(layer_sizes[-1])(enc_output)\n",
    "  z_log_sigma = Dense(layer_sizes[-1])(enc_output)\n",
    "  z = Lambda(sampling, output_shape=(layer_sizes[-1],))([z_mean, z_log_sigma])\n",
    "  encoder = Model(enc_input, z_mean, name=\"Encoder\")\n",
    "\n",
    "  # Create decoder model\n",
    "  bottleneck_size = layer_sizes[-1]\n",
    "  dec_input = Input((bottleneck_size,))\n",
    "  layer = RepeatVector(timesteps)\n",
    "  x = layer(z)\n",
    "  _x = layer(dec_input)\n",
    "  for layer_size in layer_sizes[::-1][1:]:\n",
    "    layer = Bidirectional(LSTM(layer_size, return_sequences=True))\n",
    "    x = layer(x)\n",
    "    _x = layer(_x)\n",
    "  layer =  TimeDistributed(Dense(vocab_size, activation=\"softmax\"))\n",
    "  dec_output = layer(x)\n",
    "  _dec_output = layer(_x)\n",
    "  decoder = Model(dec_input, _dec_output, name=\"Decoder\")\n",
    "\n",
    "  # connected_decoder = decoder(z_mean)\n",
    "\n",
    "  # Create autoencoder model\n",
    "  autoencoder = Model(enc_input, dec_output, name=\"Autoencoder\")\n",
    "  # autoencoder = Model(enc_input, connected_decoder, name=\"Autoencoder\")\n",
    "\n",
    "  # Variational autoencoder custom loss categorical entropy loss + KL loss\n",
    "  def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = objectives.categorical_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    xent_loss = K.sum(xent_loss, axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "  autoencoder.compile(loss=vae_loss, optimizer=\"adam\", metrics=['categorical_accuracy'], experimental_run_tf_function=False)\n",
    "  return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8207,
     "status": "ok",
     "timestamp": 1620980802909,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 420
    },
    "id": "riDg3q0xgkpB",
    "outputId": "e3ddadfb-0960-4030-e8eb-9a41f5a84835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"Encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(10, 49, 56)]            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (10, 49, 32)              9344      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (10, 49, 20)              3440      \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (10, 12)                  1296      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (10, 6)                   78        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (10, 6)                   42        \n",
      "=================================================================\n",
      "Total params: 14,200\n",
      "Trainable params: 14,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) multiple                  0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection multiple                  1360      \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection multiple                  4736      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri multiple                  1848      \n",
      "=================================================================\n",
      "Total params: 7,944\n",
      "Trainable params: 7,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "variational_encoder, variational_decoder, variational_autoencoder = create_lstm_vae(PASS_LENGTH, [16, 10, 6], vocab_size)\n",
    "variational_encoder.summary()\n",
    "variational_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wMqbhT7V4Is_",
    "outputId": "7275909b-561b-4081-e660-70af52d68d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 24s 24ms/sample - loss: 123.9632 - categorical_accuracy: 0.3032\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 24s 24ms/sample - loss: 123.9206 - categorical_accuracy: 0.3029\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 24s 24ms/sample - loss: 123.9246 - categorical_accuracy: 0.3028\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 24s 24ms/sample - loss: 123.6002 - categorical_accuracy: 0.3046\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 24s 24ms/sample - loss: 123.9897 - categorical_accuracy: 0.3021\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 24s 24ms/sample - loss: 123.6095 - categorical_accuracy: 0.3040\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 24s 24ms/sample - loss: 124.0095 - categorical_accuracy: 0.3019\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 24s 24ms/sample - loss: 123.9707 - categorical_accuracy: 0.3028\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 24s 24ms/sample - loss: 123.5180 - categorical_accuracy: 0.3038\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 24s 24ms/sample - loss: 123.7192 - categorical_accuracy: 0.3026\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 24s 24ms/sample - loss: 123.6220 - categorical_accuracy: 0.3033\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 24s 24ms/sample - loss: 123.4929 - categorical_accuracy: 0.3049\n",
      "Epoch 90/300\n",
      " 100/1000 [==>...........................] - ETA: 21s - loss: 124.1184 - categorical_accuracy: 0.2935"
     ]
    }
   ],
   "source": [
    "variational_autoencoder.fit(one_hot_encoded, one_hot_encoded, epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3343519,
     "status": "ok",
     "timestamp": 1620280938756,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "Tr0yx6JW432-",
    "outputId": "63903346-78a3-452d-c7f2-9931464fd26c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "# Recosntruct passwords through autoencoder as vectors\n",
    "reconst_passwd_vecs = variational_autoencoder.predict(one_hot_encoded, batch_size=10)\n",
    "# Reverse one hot encoding to covnert passwords to strings\n",
    "unpad = lambda text: text.replace(PAD_CHAR, \"\")\n",
    "one_hot_decode = lambda one_hot_vectors: \"\".join([list(charset)[np.argmax(vec)] for vec in one_hot_vectors])\n",
    "reconst_passwd_str = [unpad(one_hot_decode(p)) for p in reconst_passwd_vecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 3343518,
     "status": "ok",
     "timestamp": 1620280938764,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "uoD_CrqLrtJa",
    "outputId": "a55f24d2-0f76-42d6-cb89-84722a7fd7dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Password</th>\n",
       "      <th>Recosntructed Password</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acafe2019!</td>\n",
       "      <td>Acafe2019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahyper2019!</td>\n",
       "      <td>Ahyper2019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pleet10!</td>\n",
       "      <td>Aleet10!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ababe2!</td>\n",
       "      <td>Ababe1!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tbingo1234*</td>\n",
       "      <td>Abingo1234!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eleet2019@</td>\n",
       "      <td>Aleet2019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tninja123!</td>\n",
       "      <td>Aninja1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aninja777*</td>\n",
       "      <td>Aninja123*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ababe101*</td>\n",
       "      <td>Ababe111!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tbingo2019_</td>\n",
       "      <td>Abingo2019!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Original Password Recosntructed Password\n",
       "0        Acafe2019!             Acafe2019!\n",
       "1       Ahyper2019!            Ahyper2019!\n",
       "2          Pleet10!               Aleet10!\n",
       "3           Ababe2!                Ababe1!\n",
       "4       Tbingo1234*            Abingo1234!\n",
       "5        Eleet2019@             Aleet2019!\n",
       "6        Tninja123!             Aninja1234\n",
       "7        Aninja777*             Aninja123*\n",
       "8         Ababe101*              Ababe111!\n",
       "9       Tbingo2019_            Abingo2019!"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare original vs reconstructed passwords\n",
    "passwords_df = pd.DataFrame(zip(passwords[\"FullPassword\"], reconst_passwd_str),\n",
    "                            columns = ['Original Password', 'Recosntructed Password'])\n",
    "passwords_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate New Passwords and Calculate the Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "executionInfo": {
     "elapsed": 3345739,
     "status": "ok",
     "timestamp": 1620280940995,
     "user": {
      "displayName": "Zihao Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiL39Gkr9ULyAAnILNAWRoIYn6ms1WGRSv5r-Z1=s64",
      "userId": "08268785162675076394"
     },
     "user_tz": 240
    },
    "id": "bKjsoUoRsEsy",
    "outputId": "aa03befa-38ec-4f78-efd1-9837b7ab5974"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Password</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ababe2!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tleet2!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAyceemannn27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aleet0019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahabe2!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abingg201!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abingo1219!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ahackerm1n2019!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abigo1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abingo111!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Password\n",
       "0          Ababe2!\n",
       "1          Tleet2!\n",
       "2    AAyceemannn27\n",
       "3       Aleet0019!\n",
       "4          Ahabe2!\n",
       "5       Abingg201!\n",
       "6      Abingo1219!\n",
       "7  Ahackerm1n2019!\n",
       "8           Abigo1\n",
       "9       Abingo111!"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install BiEntropy\n",
    "\n",
    "from bientropy import bien, tbien\n",
    "import random\n",
    "\n",
    "sum_entropy = 0\n",
    "max_entropy = float('-inf')\n",
    "min_entropy = float('inf')\n",
    "\n",
    "mu, sigma = 0, 3\n",
    "new_passwords = []\n",
    "entropy = []\n",
    "i = 0\n",
    "while i < 1000:\n",
    "  latent_sample = np.array([np.random.normal(mu, sigma, 6)])\n",
    "  new_password_vec = variational_decoder.predict(latent_sample)\n",
    "  new_password_str = unpad(one_hot_decode(new_password_vec[0]))\n",
    "\n",
    "  pswd_bytes = bytes(new_password_str, 'utf-8')\n",
    "  e = tbien(pswd_bytes)\n",
    "  \n",
    "  # Threshold\n",
    "  if e > 0.5:\n",
    "    entropy.append(e)\n",
    "    sum_entropy += e\n",
    "    # update the max and the min entropy\n",
    "    max_entropy = max(max_entropy, e)\n",
    "    min_entropy = min(min_entropy, e)\n",
    "    \n",
    "    new_passwords.append(new_password_str)\n",
    "    i += 1\n",
    "    \n",
    "avg_entropy = sum_entropy / len(new_passwords)\n",
    "\n",
    "print(\"MAX entropy: \" + str(max_entropy))\n",
    "print(\"MIN entropy: \" + str(min_entropy))\n",
    "print(\"AVG entropy: \" + str(avg_entropy))\n",
    "\n",
    "new_passwords_entropy_df = pd.DataFrame(new_passwords, columns=[\"Password\"])\n",
    "\n",
    "# Save them into a CSV file\n",
    "new_passwords_df.to_csv(path + 'data/output/gupass_vae_sample_pass.csv', sep=',')\n",
    "\n",
    "new_passwords_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GUPass_Variational_Autoencoder_Generating_Passwords.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
